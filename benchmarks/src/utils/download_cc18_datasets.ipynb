{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0521be8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 35 binary tasks in CC-18.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading & writing: 100%|██████████| 35/35 [05:43<00:00,  9.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All done.\n",
      "CSV files are in   /home/ariel/prog/yggdrasil-oblique-forests/benchmarks/src/utils/cc18_binary_csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# requirements\n",
    "# ------------------------------------------------------------\n",
    "#   pip install openml pandas tqdm\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "import openml\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# Where the csv files should be written\n",
    "DEST_DIR = \"cc18_binary_csv\"\n",
    "os.makedirs(DEST_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. get the list of *binary* CC-18 tasks\n",
    "# ------------------------------------------------------------\n",
    "binary_tasks_df = openml.tasks.list_tasks(\n",
    "    tag=\"OpenML-CC18\",\n",
    "    type=1,                 # 1 = classification\n",
    "    number_classes=2,       # keep only binary problems\n",
    "    output_format=\"dataframe\"\n",
    ")\n",
    "\n",
    "binary_task_ids = binary_tasks_df.index.tolist()\n",
    "print(f\"Found {len(binary_task_ids)} binary tasks in CC-18.\")\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. loop through the tasks and materialise the splits\n",
    "# ------------------------------------------------------------\n",
    "for tid in tqdm(binary_task_ids, desc=\"downloading & writing\"):\n",
    "    task    = openml.tasks.get_task(tid, download_data=False)\n",
    "    dset    = task.get_dataset()\n",
    "    dname   = dset.name                    # e.g. 'banana'\n",
    "    target  = dset.default_target_attribute\n",
    "\n",
    "    # Obtain the full dataframe once\n",
    "    X, y, _, _ = dset.get_data(dataset_format=\"dataframe\",\n",
    "                               target=target)\n",
    "                            #    handle_missing=True)   # gives NaNs where needed\n",
    "    df = X.copy()\n",
    "    df[target] = y\n",
    "\n",
    "    task_dir = os.path.join(DEST_DIR, f\"task_{tid}_{dname}\")\n",
    "    os.makedirs(task_dir, exist_ok=True)\n",
    "\n",
    "    # Iterate over the predefined CV splits\n",
    "    # ------------------------------------------------------------------\n",
    "    # NEW helper --------------------------------------------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    def _n(param_dict, key, default=1):\n",
    "        \"\"\"Return an int(parameter_dict[key]) or a default value.\"\"\"\n",
    "        return int(param_dict.get(key, default))\n",
    "\n",
    "    # ------------------------------------------------------------------\n",
    "    # inside the main loop, *after* we created `task`  ------------------\n",
    "    # ------------------------------------------------------------------\n",
    "    est_params = task.estimation_procedure.get(\"parameters\", {})  # note: \"parameters\"\n",
    "    n_repeats = int(est_params.get(\"number_repeats\", 1))\n",
    "    n_folds = int(est_params.get(\"number_folds\", 1))\n",
    "    n_samples = int(est_params.get(\"number_samples\", 1))  # often 1\n",
    "\n",
    "    # Iterate over the predefined CV splits ----------------------------\n",
    "    for repeat in range(n_repeats):\n",
    "        for fold in range(n_folds):\n",
    "            for sample in range(n_samples):            # most tasks: sample = 0 only\n",
    "                train_idx, test_idx = task.get_train_test_split_indices(\n",
    "                    repeat=repeat, fold=fold, sample=sample\n",
    "                )\n",
    "\n",
    "                train_path = os.path.join(\n",
    "                    task_dir, f\"repeat{repeat}_fold{fold}_sample{sample}_train.csv\"\n",
    "                )\n",
    "                test_path = os.path.join(\n",
    "                    task_dir, f\"repeat{repeat}_fold{fold}_sample{sample}_test.csv\"\n",
    "                )\n",
    "\n",
    "                df.iloc[train_idx].to_csv(train_path, index=False)\n",
    "                df.iloc[test_idx].to_csv(test_path,  index=False)\n",
    "\n",
    "print(\"\\nAll done.\")\n",
    "print(f\"CSV files are in   {os.path.abspath(DEST_DIR)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057da9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
